# utils/function_calling_system.py

import os
import json
import sqlite3
from typing import List, Dict, Any, Optional
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_community.vectorstores import Chroma
from langchain_core.messages import HumanMessage, AIMessage
from langchain_core.tools import tool
from utils.prompts.recall_prompts import RecallPrompts

load_dotenv()

# ì „ì—­ ë³€ìˆ˜ - ì‹œìŠ¤í…œ ì»´í¬ë„ŒíŠ¸ë“¤
_sqlite_conn = None
_vectorstore = None  
_logical_processor = None
_db_initialized = False

def initialize_sqlite_db(db_path="./data/fda_recalls.db"):
    """SQLite ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì´ˆê¸°í™” (ìŠ¤ë ˆë“œ ì•ˆì „)"""
    try:
        if not os.path.exists(db_path):
            print(f"âŒ SQLite ë°ì´í„°ë² ì´ìŠ¤ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {db_path}")
            return None
        
        # ğŸ”§ ìŠ¤ë ˆë“œ ì•ˆì „ ì„¤ì •
        conn = sqlite3.connect(
            db_path, 
            check_same_thread=False,  # ìŠ¤ë ˆë“œ ì•ˆì „ì„± í•´ì œ
            timeout=30.0  # íƒ€ì„ì•„ì›ƒ ì„¤ì •
        )
        conn.row_factory = sqlite3.Row
        
        cursor = conn.cursor()
        cursor.execute("SELECT COUNT(*) as count FROM recalls")
        total_records = cursor.fetchone()['count']
        print(f"âœ… SQLite ì—°ê²° ì„±ê³µ: {total_records}ê°œ ë ˆì½”ë“œ")
        
        return conn
        
    except Exception as e:
        print(f"âŒ SQLite ì—°ê²° ì‹¤íŒ¨: {e}")
        return None

def initialize_recall_vectorstore():
    """ChromaDB ë²¡í„°ìŠ¤í† ì–´ ì´ˆê¸°í™”"""
    persist_dir = "./data/chroma_db_recall"
    
    if os.path.exists(persist_dir) and os.listdir(persist_dir):
        try:
            print("ê¸°ì¡´ ë¦¬ì½œ ë²¡í„°ìŠ¤í† ì–´ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤...")
            embeddings = OpenAIEmbeddings(model="text-embedding-3-small")
            
            vectorstore = Chroma(
                persist_directory=persist_dir,
                embedding_function=embeddings,
                collection_name="FDA_recalls"
            )
            
            collection = vectorstore._collection
            doc_count = collection.count()
            print(f"âœ… ë¦¬ì½œ ë²¡í„°ìŠ¤í† ì–´ ë¡œë“œ ì™„ë£Œ ({doc_count}ê°œ ë¬¸ì„œ)")
            return vectorstore
                
        except Exception as e:
            print(f"âš ï¸ ë²¡í„°ìŠ¤í† ì–´ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return None
    else:
        print("âš ï¸ ë²¡í„°ìŠ¤í† ì–´ í´ë”ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤")
        return None
    
def parse_relative_dates(period_text: str) -> str:
    """ìƒëŒ€ì  ë‚ ì§œ í‘œí˜„ì„ ì ˆëŒ€ ì—°ë„ë¡œ ë³€í™˜ (2025ë…„ ê¸°ì¤€)"""
    import datetime
    
    current_year = datetime.datetime.now().year  # 2025
    
    # ğŸ”§ ì˜¬ë°”ë¥¸ í•œêµ­ì–´ í‘œí˜„ ë§¤í•‘
    korean_mappings = {
        "ì˜¬í•´": str(current_year),           # 2025 âœ…
        "ì‘ë…„": str(current_year - 1),       # 2024 âœ…  
        "ì¬ì‘ë…„": str(current_year - 2),     # 2023 âœ…
        "ì´ë²ˆë…„": str(current_year),         # 2025
        "í˜„ì¬": str(current_year),           # 2025
        "ì§€ë‚œí•´": str(current_year - 1),     # 2024 âœ…
        "ì „ë…„": str(current_year - 1),       # 2024 âœ…
        "ê¸ˆë…„": str(current_year),           # 2025
        "ì‘ë…„ë„": str(current_year - 1),     # 2024
        "ì˜¬í•´ë…„ë„": str(current_year),       # 2025
    }
    
    period_lower = period_text.lower().strip()
    
    # í•œêµ­ì–´ ë§¤í•‘ í™•ì¸
    for korean, year in korean_mappings.items():
        if korean in period_lower:
            print(f"ğŸ”§ ë‚ ì§œ ë§¤í•‘: '{period_text}' â†’ {year}ë…„ (í˜„ì¬: {current_year})")
            return year
    
    # ìˆ«ìì¸ ê²½ìš° ê·¸ëŒ€ë¡œ ë°˜í™˜
    if period_text.isdigit() and len(period_text) == 4:
        return period_text
    
    # ì¸ì‹í•˜ì§€ ëª»í•œ ê²½ìš° í˜„ì¬ ì—°ë„ ë°˜í™˜
    print(f"âš ï¸ ë‚ ì§œ ì¸ì‹ ì‹¤íŒ¨: '{period_text}' â†’ ê¸°ë³¸ê°’ {current_year}ë…„ ì‚¬ìš©")
    return str(current_year)

def translate_to_english(korean_text: str) -> str:
    """í•œêµ­ì–´ í…ìŠ¤íŠ¸ë¥¼ ì˜ì–´ë¡œ ë²ˆì—­í•˜ëŠ” í•¨ìˆ˜"""
    from langchain_openai import ChatOpenAI
    
    try:
        translator = ChatOpenAI(
            model="gpt-3.5-turbo",
            temperature=0
        )
        
        translation_prompt = f"""
ë‹¤ìŒ í•œêµ­ì–´ í…ìŠ¤íŠ¸ë¥¼ ì˜ì–´ë¡œ ì •í™•íˆ ë²ˆì—­í•´ì£¼ì„¸ìš”. 
ì‹í’ˆ, ë¦¬ì½œ, ì•Œë ˆë¥´ê² ê´€ë ¨ ì „ë¬¸ ìš©ì–´ëŠ” FDA í‘œì¤€ ìš©ì–´ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.

í•œêµ­ì–´: {korean_text}
ì˜ì–´:"""
        
        response = translator.invoke([{"role": "user", "content": translation_prompt}])
        english_text = response.content.strip()
        
        print(f"ğŸ”„ ë²ˆì—­: '{korean_text}' â†’ '{english_text}'")
        return english_text
        
    except Exception as e:
        print(f"ë²ˆì—­ ì˜¤ë¥˜: {e}")
        # ë²ˆì—­ ì‹¤íŒ¨ ì‹œ ê¸°ì¡´ í‚¤ì›Œë“œ ë§¤í•‘ ì‚¬ìš©
        return korean_text

def get_recall_vectorstore():
    """tab_recall.py í˜¸í™˜ìš© í•¨ìˆ˜"""
    return initialize_recall_vectorstore()

def _get_system_components():
    global _sqlite_conn, _vectorstore, _db_initialized
    
    if not _db_initialized:
        _sqlite_conn = initialize_sqlite_db()
        _vectorstore = initialize_recall_vectorstore()
        _db_initialized = True
    
    return _sqlite_conn, _vectorstore, None  

# ======================
# Function Calling ë„êµ¬ë“¤
# ======================

@tool
def count_recalls(company: Optional[str] = None,
                 food_type: Optional[str] = None, 
                 allergen: Optional[str] = None,
                 contaminant: Optional[str] = None,
                 year: Optional[str] = None,
                 recall_reason: Optional[str] = None,
                 keyword: Optional[str] = None) -> Dict[str, Any]:  # ğŸ†• í†µí•© í‚¤ì›Œë“œ ì¶”ê°€
    """ë¦¬ì½œ ê±´ìˆ˜ë¥¼ ì„¸ëŠ” í•¨ìˆ˜ (SQLite ê¸°ë°˜) - ë‹¤ì¤‘ í•„ë“œ í†µí•© ê²€ìƒ‰ ì§€ì›"""
    
    sqlite_conn, _, _ = _get_system_components()
    
    if not sqlite_conn:
        return {"error": "SQLite ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨"}
    
    try:
        sql = "SELECT COUNT(*) as count FROM recalls WHERE 1=1"
        params = []
        
        # ğŸ†• í†µí•© í‚¤ì›Œë“œ ê²€ìƒ‰ (ì—¬ëŸ¬ í•„ë“œì—ì„œ ë™ì‹œ ê²€ìƒ‰)
        if keyword:
            # ğŸ†• í•œêµ­ì–´ í‚¤ì›Œë“œë¥¼ ì˜ì–´ë¡œ ë²ˆì—­
            english_keyword = translate_to_english(keyword)
            search_terms = [keyword, english_keyword]  # ì›ë³¸ê³¼ ë²ˆì—­ë³¸ ëª¨ë‘ ì‚¬ìš©
            
            print(f"ğŸ” ê²€ìƒ‰ì–´: {search_terms}")
            
            search_conditions = []
            for term in search_terms:
                search_conditions.append("""(
                    LOWER(ont_food_type) LIKE LOWER(?) OR 
                    LOWER(ont_food) LIKE LOWER(?) OR
                    LOWER(ont_allergen) LIKE LOWER(?) OR
                    LOWER(ont_contaminant) LIKE LOWER(?) OR
                    LOWER(ont_recall_reason) LIKE LOWER(?) OR
                    LOWER(ont_company) LIKE LOWER(?)
                )""")
                params.extend([f"%{term}%"] * 6)
            
            sql += f" AND ({' OR '.join(search_conditions)})"
        
        # ê¸°ì¡´ ê°œë³„ í•„í„°ë“¤
        if company:
            english_company = translate_to_english(company)
            company_terms = [company, english_company] if english_company != company else [company]
            company_conditions = []
            for term in company_terms:
                company_conditions.append("LOWER(ont_company) LIKE LOWER(?)")  # company â†’ ont_company
                params.append(f"%{term}%")
            sql += f" AND ({' OR '.join(company_conditions)})"
            
        if food_type:
            english_food_type = translate_to_english(food_type)
            food_type_terms = [food_type, english_food_type] if english_food_type != food_type else [food_type]
            food_type_conditions = []
            for term in food_type_terms:
                food_type_conditions.append("LOWER(ont_food_type) LIKE LOWER(?)")  # food_type â†’ ont_food_type
                params.append(f"%{term}%")
            sql += f" AND ({' OR '.join(food_type_conditions)})"
            
        if allergen:
            english_allergen = translate_to_english(allergen)
            allergen_terms = [allergen, english_allergen] if english_allergen != allergen else [allergen]
            allergen_conditions = []
            for term in allergen_terms:
                allergen_conditions.append("LOWER(ont_allergen) LIKE LOWER(?)")  # allergen â†’ ont_allergen
                params.append(f"%{term}%")
            sql += f" AND ({' OR '.join(allergen_conditions)})"

        if contaminant:
            english_contaminant = translate_to_english(contaminant)
            contaminant_terms = [contaminant, english_contaminant] if english_contaminant != contaminant else [contaminant]
            contaminant_conditions = []
            for term in contaminant_terms:
                contaminant_conditions.append("LOWER(ont_contaminant) LIKE LOWER(?)")  # contaminant â†’ ont_contaminant
                params.append(f"%{term}%")
            sql += f" AND ({' OR '.join(contaminant_conditions)})"
            
        if recall_reason:
            english_recall_reason = translate_to_english(recall_reason)
            recall_reason_terms = [recall_reason, english_recall_reason] if english_recall_reason != recall_reason else [recall_reason]
            recall_reason_conditions = []
            for term in recall_reason_terms:
                recall_reason_conditions.append("LOWER(ont_recall_reason) LIKE LOWER(?)")  # recall_reason â†’ ont_recall_reason
                params.append(f"%{term}%")
            sql += f" AND ({' OR '.join(recall_reason_conditions)})"
        if year:
            sql += " AND strftime('%Y', effective_date) = ?"
            params.append(year)
        
        print(f"ğŸ”§ í†µí•© ê²€ìƒ‰ SQL: {sql}")
        print(f"ğŸ”§ íŒŒë¼ë¯¸í„°: {params}")
        
        cursor = sqlite_conn.cursor()
        cursor.execute(sql, params)
        result = cursor.fetchone()
        
        return {
            "count": result["count"],
            "filters": {
                "company": company, "food_type": food_type,
                "allergen": allergen, "contaminant": contaminant, 
                "year": year, "recall_reason": recall_reason,
                "keyword": keyword  # ğŸ†• ì¶”ê°€
            },
            "search_fields": "multiple" if keyword else "specific",  # ğŸ†• ê²€ìƒ‰ ë°©ì‹ í‘œì‹œ
            "query_type": "unified_count"
        }
        
    except Exception as e:
        return {"error": f"SQL ì¹´ìš´íŒ… ì˜¤ë¥˜: {e}"}

@tool
def rank_by_field(field: str, limit: int = 10, 
                 company: Optional[str] = None,
                 food_type: Optional[str] = None,
                 year: Optional[str] = None) -> Dict[str, Any]:
    """í•„ë“œë³„ ìˆœìœ„ (ë‹¤ì¸µ í•„ë“œ ê²€ìƒ‰ ì§€ì›)"""
    
    sqlite_conn, _, _ = _get_system_components()
    
    if not sqlite_conn:
        return {"error": "SQLite ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨"}
    
    try:
        cursor = sqlite_conn.cursor()
        
        # ğŸ†• ë‹¤ì¸µ í•„ë“œ ë§¤í•‘
        field_mapping = {
        "company": "ont_company",
        "food_type": "ont_food_type",           # ë‹¨ì¼ í•„ë“œ
        "food": "ont_food",             
        "recall_reason": "ont_recall_reason",
        "allergen": "ont_allergen",
        "contaminant": "ont_contaminant"
    }
        
        db_fields = field_mapping.get(field.lower(), ["company"])
        if isinstance(db_fields, str):
            db_fields = [db_fields]
        
        # ğŸ†• ë‹¤ì¸µ ê²€ìƒ‰ SQL êµ¬ì„±
        if len(db_fields) > 1:
            # COALESCEë¡œ ë‹¤ì¸µ í•„ë“œ í†µí•©
            select_field = f"COALESCE({', '.join(db_fields)}) as name"
            where_conditions = []
            for db_field in db_fields:
                where_conditions.append(f"{db_field} IS NOT NULL AND {db_field} != '' AND {db_field} != 'N/A'")
            where_clause = "(" + " OR ".join(where_conditions) + ")"
        else:
            select_field = f"{db_fields[0]} as name"
            where_clause = f"{db_fields[0]} IS NOT NULL AND {db_fields[0]} != '' AND {db_fields[0]} != 'N/A'"
        
        sql = f"""
            SELECT {select_field}, COUNT(*) as count 
            FROM recalls 
            WHERE {where_clause}
        """
        params = []
        
        # ê¸°ì¡´ í•„í„° ì¡°ê±´ë“¤
        if company and db_fields[0] != "ont_company":
            sql += " AND LOWER(ont_company) LIKE LOWER(?)"
            params.append(f"%{company}%")
            
        if food_type and db_fields[0] != "ont_food_type":
            sql += " AND LOWER(ont_food_type) LIKE LOWER(?)"
            params.append(f"%{food_type}%")
            
        if year:
            sql += " AND strftime('%Y', effective_date) = ?"
            params.append(year)

        sql += f" GROUP BY name ORDER BY count DESC LIMIT ?"
        params.append(limit)
        
        print(f"ğŸ”§ ë‹¤ì¸µ ê²€ìƒ‰ SQL: {sql}")
        print(f"ğŸ”§ íŒŒë¼ë¯¸í„°: {params}")
        
        cursor.execute(sql, params)
        results = [{"name": row["name"], "count": row["count"]} for row in cursor.fetchall()]
        
        return {
            "ranking": results,
            "field": field,
            "search_fields": db_fields,  # ê²€ìƒ‰í•œ í•„ë“œë“¤ í‘œì‹œ
            "total_items": len(results),
            "query_type": "multilayer_ranking"
        }
        
    except Exception as e:
        return {"error": f"ë‹¤ì¸µ ìˆœìœ„ ì¡°íšŒ ì˜¤ë¥˜: {e}"}
    
@tool 
def get_monthly_trend(months: int = 12,
                     food_type: Optional[str] = None,
                     company: Optional[str] = None) -> Dict[str, Any]:
    """ì›”ë³„ ë¦¬ì½œ íŠ¸ë Œë“œë¥¼ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜ (SQLite ê¸°ë°˜)"""
    sqlite_conn, _, _ = _get_system_components()
    
    if not sqlite_conn:
        return {"error": "SQLite ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨"}
    
    try:
        sql = """
            SELECT strftime('%Y-%m', effective_date) as month, COUNT(*) as count
            FROM recalls 
            WHERE effective_date IS NOT NULL
        """
        params = []
        
        if food_type:
            sql += " AND LOWER(ont_food_type) LIKE LOWER(?)"
            params.append(f"%{food_type}%")
        if company:
            sql += " AND LOWER(ont_company) LIKE LOWER(?)"
            params.append(f"%{company}%")
        
        sql += " GROUP BY month ORDER BY month DESC LIMIT ?"
        params.append(months)
        
        cursor = sqlite_conn.cursor()
        cursor.execute(sql, params)
        results = [{"month": row["month"], "count": row["count"]} for row in cursor.fetchall()]
        
        return {
            "trend": results, 
            "months": months,
            "query_type": "trend"
        }
        
    except Exception as e:
        return {"error": f"íŠ¸ë Œë“œ ì¡°íšŒ ì˜¤ë¥˜: {e}"}

@tool
def compare_periods(period1: str, period2: str, 
                   metric: str = "count",
                   include_reasons: bool = False) -> Dict[str, Any]:  # ğŸ†• ë§¤ê°œë³€ìˆ˜ ì¶”ê°€
    """ê¸°ê°„ë³„ ë¹„êµ ë¶„ì„ í•¨ìˆ˜ (ìì—°ì–´ ë‚ ì§œ ì§€ì› + ì‚¬ìœ ë³„ ë¶„ì„)"""
    
    sqlite_conn, _, _ = _get_system_components()
    
    if not sqlite_conn:
        return {"error": "SQLite ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨"}
    
    try:
        # ğŸ†• ìƒëŒ€ì  ë‚ ì§œ í‘œí˜„ì„ ì ˆëŒ€ ì—°ë„ë¡œ ë³€í™˜
        actual_period1 = parse_relative_dates(period1)
        actual_period2 = parse_relative_dates(period2)
        
        print(f"ğŸ”§ ë‚ ì§œ ë³€í™˜: '{period1}' â†’ {actual_period1}, '{period2}' â†’ {actual_period2}")
        
        cursor = sqlite_conn.cursor()
        
        def get_period_data(period: str):
            if len(period) == 4:  # ì—°ë„
                date_filter = "strftime('%Y', effective_date) = ?"
            elif len(period) == 7:  # ì—°ì›”
                date_filter = "strftime('%Y-%m', effective_date) = ?"
            else:
                return None
            
            result_data = {}
            
            # ê¸°ë³¸ ì¹´ìš´íŠ¸
            if metric == "count":
                sql = f"SELECT COUNT(*) as value FROM recalls WHERE {date_filter}"
            elif metric == "companies":
                sql = f"SELECT COUNT(DISTINCT ont_company) as value FROM recalls WHERE {date_filter} AND company IS NOT NULL"
            elif metric == "food_types":
                sql = f"SELECT COUNT(DISTINCT ont_food_type) as value FROM recalls WHERE {date_filter} AND food_type IS NOT NULL"
            
            cursor.execute(sql, [period])
            result = cursor.fetchone()
            result_data["total"] = result["value"] if result else 0
            
            # ğŸ†• ë¦¬ì½œ ì‚¬ìœ ë³„ ë¶„ì„ ì¶”ê°€ (ë¦¬ì½œ ì›ì¸ ë¹„êµ ì§ˆë¬¸ìš©)
            if include_reasons or "ì›ì¸" in str(period) or "ì‚¬ìœ " in str(period):
                cursor.execute(f"""
                    SELECT recall_reason, COUNT(*) as count 
                    FROM recalls 
                    WHERE {date_filter} AND recall_reason IS NOT NULL
                    GROUP BY recall_reason 
                    ORDER BY count DESC 
                    LIMIT 5
                """, [period])
                reasons = [{"reason": row["recall_reason"], "count": row["count"]} for row in cursor.fetchall()]
                result_data["top_reasons"] = reasons
            
            return result_data
        
        data1 = get_period_data(actual_period1)
        data2 = get_period_data(actual_period2)
        
        if data1 is None or data2 is None:
            return {"error": "ì˜ëª»ëœ ê¸°ê°„ í˜•ì‹ì…ë‹ˆë‹¤. YYYY ë˜ëŠ” YYYY-MM í˜•ì‹ì„ ì‚¬ìš©í•˜ì„¸ìš”."}
        
        # ë³€í™”ìœ¨ ê³„ì‚° (ì´ ê±´ìˆ˜ ê¸°ì¤€)
        value1 = data1.get("total", 0)
        value2 = data2.get("total", 0)
        change = value2 - value1
        change_percent = (change / value1 * 100) if value1 > 0 else 0
        
        return {
            "period1": {"period": f"{period1}({actual_period1})", "data": data1},  # ğŸ†• êµ¬ì¡° ë³€ê²½
            "period2": {"period": f"{period2}({actual_period2})", "data": data2},  # ğŸ†• êµ¬ì¡° ë³€ê²½
            "change": change,
            "change_percent": round(change_percent, 1),
            "metric": metric,
            "query_type": "enhanced_period_comparison",
            "actual_periods": [actual_period1, actual_period2]
        }
        
    except Exception as e:
        return {"error": f"ê¸°ê°„ ë¹„êµ ì˜¤ë¥˜: {e}"}

@tool
def search_recall_cases(query: str, limit: int = 5) -> Dict[str, Any]:
    """ChromaDB ê¸°ë°˜ ì˜ë¯¸ì  ê²€ìƒ‰ (í•œì˜ ë²ˆì—­ ì§€ì›)"""
    

    _, vectorstore, _ = _get_system_components()
    
    if not vectorstore:
        return {"error": "ChromaDB ë²¡í„°ìŠ¤í† ì–´ ì—°ê²° ì‹¤íŒ¨"}
    
    try:
        search_queries = []
        search_queries.append(query)  # ì›ë³¸

        # ğŸ†• ì „ì²´ ì¿¼ë¦¬ ë²ˆì—­
        english_query = translate_to_english(query)
        if english_query != query:
            search_queries.append(english_query)

        print(f"ğŸ” ê²€ìƒ‰ì–´ í™•ì¥: {search_queries}")
        
        # í•µì‹¬ í‚¤ì›Œë“œ ë§¤í•‘
        translations = {
            "ì†ŒìŠ¤ë¥¼ í¬í•¨í•œ ë³µí•©ì‹í’ˆ": "sauce processed food",
            "ë³µí•© ê°€ê³µì‹í’ˆ": "processed foods",
            "ì‚´ëª¨ë„¬ë¼": "Salmonella",
            "ëŒ€ì¥ê· ": "E.coli",
            "ë¦¬ìŠ¤í…Œë¦¬ì•„": "Listeria",
            "ì•Œë ˆë¥´ê²": "allergen",
            "ì˜¤ì—¼": "contamination",
            "ë¦¬ì½œ ì‚¬ë¡€": "recall cases"
        }
        
        # ì „ì²´ ë¬¸ì¥ ë²ˆì—­
        english_query = query
        for ko_term, en_term in translations.items():
            if ko_term in english_query:
                english_query = english_query.replace(ko_term, en_term)
        
        if english_query != query:
            search_queries.append(english_query)
        
        # ê°œë³„ í‚¤ì›Œë“œ ì¶”ì¶œ ë° ë²ˆì—­
        for ko_term, en_term in translations.items():
            if ko_term in query:
                search_queries.append(en_term)
        
        print(f"ğŸ” ê²€ìƒ‰ì–´ í™•ì¥: {search_queries}")
        
        all_docs = []
        seen_urls = set()
        
        # ê° ê²€ìƒ‰ì–´ë¡œ ê²€ìƒ‰ ì‹¤í–‰
        for search_query in search_queries:
            docs = vectorstore.similarity_search(
                search_query, 
                k=limit * 2,
                filter={"document_type": "recall"}
            )
            
            for doc in docs:
                url = doc.metadata.get("url", "")
                if url not in seen_urls:
                    all_docs.append(doc)
                    seen_urls.add(url)
        
        # ìƒìœ„ ê²°ê³¼ ì„ íƒ
        selected_docs = all_docs[:limit]
        

        # ê²°ê³¼ í¬ë§·íŒ…
        cases = []
        for doc in selected_docs:
            cases.append({
                "title": doc.metadata.get("title", ""),
                "company": doc.metadata.get("ont_company", "Unknown"),
                "food": doc.metadata.get("ont_food", ""),
                "reason": doc.metadata.get("ont_recall_reason", ""),
                "allergen": doc.metadata.get("ont_allergen", ""),
                "date": doc.metadata.get("effective_date", ""),
                "url": doc.metadata.get("url", ""),
                "content_preview": doc.page_content[:200] + "..."
            })
        
        return {
            "cases": cases,
            "total_found": len(cases),
            "original_query": query,
            "search_queries": search_queries,
            "search_method": "multilingual_search"
        }
        
    except Exception as e:
        return {"error": f"ê²€ìƒ‰ ì˜¤ë¥˜: {e}"}

@tool
def filter_exclude_conditions(exclude_terms: List[str],
                             include_terms: Optional[List[str]] = None) -> Dict[str, Any]:
    """íŠ¹ì • ì¡°ê±´ì„ ì œì™¸í•œ ë°ì´í„°ë¥¼ í•„í„°ë§í•˜ëŠ” í•¨ìˆ˜ (ChromaDB ê¸°ë°˜)
    
    Args:
        exclude_terms: ì œì™¸í•  ì¡°ê±´ë“¤ (ì˜ˆ: ["ìœ ì œí’ˆ", "Dairy"])
        include_terms: í¬í•¨í•  ì¡°ê±´ë“¤ (ì„ íƒì‚¬í•­)
    """
    _, _, logical_processor = _get_system_components()
    
    if not logical_processor:
        return {"error": "ë…¼ë¦¬ í”„ë¡œì„¸ì„œ ì´ˆê¸°í™” ì‹¤íŒ¨ (ChromaDB í•„ìš”)"}
    
    try:
        question = f"ë¦¬ì½œ ì‚¬ë¡€ì—ì„œ {', '.join(exclude_terms)}ë¥¼ ì œì™¸í•œ ë°ì´í„°"
        if include_terms:
            question = f"{', '.join(include_terms)} ì¤‘ì—ì„œ {', '.join(exclude_terms)}ë¥¼ ì œì™¸í•œ ë°ì´í„°"
        
        result = logical_processor.process_logical_query(question)
        
        if 'error' in result:
            return {"error": result['error']}
        
        filtered_count = 0
        excluded_count = 0
        
        if result.get('type') == 'exclude':
            filtered_count = result['result'].get('final_count', 0)
            excluded_count = result['result'].get('excluded_count', 0)
        
        return {
            "filtered_count": filtered_count,
            "excluded_count": excluded_count,
            "exclude_terms": exclude_terms,
            "include_terms": include_terms or [],
            "details": result
        }
        
    except Exception as e:
        return {"error": f"ì œì™¸ í•„í„°ë§ ì˜¤ë¥˜: {e}"}
    
@tool
def exclude_contaminant_search(include_reason: str, 
                              exclude_contaminant: str,
                              limit: int = 10) -> Dict[str, Any]:
    """íŠ¹ì • ì˜¤ì—¼ë¬¼ì§ˆì„ ì œì™¸í•œ ë¦¬ì½œ ì‚¬ë¡€ ê²€ìƒ‰ (SQLite + ChromaDB í•˜ì´ë¸Œë¦¬ë“œ)"""
    
    sqlite_conn, vectorstore, _ = _get_system_components()
    
    if not sqlite_conn:
        return {"error": "SQLite ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨"}
    
    try:
        # 1ë‹¨ê³„: SQLiteì—ì„œ ì¡°ê±´ë¶€ í•„í„°ë§
        sql = """
        SELECT id, title, ont_company, ont_food_type, ont_food, 
            ont_recall_reason, ont_allergen, ont_contaminant, effective_date, url
        FROM recalls 
        WHERE LOWER(ont_recall_reason) LIKE LOWER(?)
        AND NOT (
            LOWER(ont_contaminant) LIKE LOWER(?) OR
            LOWER(ont_allergen) LIKE LOWER(?) OR
            LOWER(ont_food) LIKE LOWER(?)
        )
        ORDER BY effective_date DESC
        LIMIT ?
        """
        
        params = [
            f"%{include_reason}%",
            f"%{exclude_contaminant}%", 
            f"%{exclude_contaminant}%",
            f"%{exclude_contaminant}%",
            limit * 2
        ]
        
        print(f"ğŸ”§ ì œì™¸ ê²€ìƒ‰ SQL: {sql}")
        print(f"ğŸ”§ íŒŒë¼ë¯¸í„°: {params}")
        
        cursor = sqlite_conn.cursor()
        cursor.execute(sql, params)
        results = cursor.fetchall()
        
        # 2ë‹¨ê³„: ChromaDBì—ì„œ ì¶”ê°€ ì‚¬ë¡€ ê²€ìƒ‰ (ì˜ì–´ í‚¤ì›Œë“œ)
        additional_cases = []
        if vectorstore and len(results) < limit:
            english_queries = [
                f"{include_reason} -salmonella",
                "bacterial contamination listeria",
                "bacterial contamination cronobacter", 
                "bacterial contamination clostridium"
            ]
            
            for query in english_queries:
                try:
                    docs = vectorstore.similarity_search(
                        query, 
                        k=5,
                        filter={"document_type": "recall"}
                    )
                    
                    for doc in docs:
                        contaminant = doc.metadata.get("ont_contaminant", "").lower()
                        if exclude_contaminant.lower() not in contaminant:
                            additional_cases.append(doc)
                            
                except Exception as e:
                    print(f"ChromaDB ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
        
        # 3ë‹¨ê³„: ê²°ê³¼ í†µí•© ë° í¬ë§·íŒ…
        final_cases = []
        
        # SQLite ê²°ê³¼ í¬ë§·íŒ…
        for row in results:
            final_cases.append({
                "title": row["title"],
                "company": row["ont_company"],
                "food_type": row["ont_food_type"],
                "food_product": row["ont_food"],
                "reason": row["ont_recall_reason"],
                "contaminant": row["ont_contaminant"],
                "allergen": row["ont_allergen"],
                "date": row["effective_date"],
                "url": row["url"]
            })
        
        # ChromaDB ê²°ê³¼ ì¶”ê°€
        for doc in additional_cases[:limit-len(final_cases)]:
            final_cases.append({
                "title": doc.metadata.get("title", ""),
                "company": doc.metadata.get("ont_company", "Unknown"),
                "food_type": doc.metadata.get("ont_food_type", ""),
                "food_product": doc.metadata.get("ont_food", ""),
                "reason": doc.metadata.get("ont_recall_reason", ""),
                "contaminant": doc.metadata.get("ont_contaminant", ""),
                "allergen": doc.metadata.get("ont_allergen", ""),
                "date": doc.metadata.get("effective_date", ""),
                "url": doc.metadata.get("url", "")
            })
        
        return {
            "cases": final_cases[:limit],
            "total_count": len(final_cases),
            "include_reason": include_reason,
            "exclude_contaminant": exclude_contaminant,
            "sqlite_results": len(results),
            "chromadb_results": len(additional_cases),
            "query_type": "exclude_contaminant_search"
        }
        
    except Exception as e:
        return {"error": f"ì œì™¸ ê²€ìƒ‰ ì˜¤ë¥˜: {e}"}
    
@tool
def filter_by_conditions(include_conditions: Optional[List[str]] = None,
                        exclude_conditions: Optional[List[str]] = None,
                        food_type: Optional[str] = None,
                        year: Optional[str] = None,
                        contaminants: Optional[List[str]] = None) -> Dict[str, Any]:  # ğŸ†• contaminants íŒŒë¼ë¯¸í„° ì¶”ê°€
    """ì¡°ê±´ë³„ í•„í„°ë§ í•¨ìˆ˜ (SQLite ê¸°ë°˜) - OR ì¡°ê±´ ì§€ì›"""
    
    sqlite_conn, _, _ = _get_system_components()
    
    if not sqlite_conn:
        return {"error": "SQLite ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨"}
    
    try:
        sql = """
        SELECT id, title, ont_company, ont_food_type, ont_food, 
               ont_recall_reason, ont_allergen, ont_contaminant, effective_date, url
        FROM recalls 
        WHERE 1=1
        """
        params = []
        
        # ì‹í’ˆ ìœ í˜• í•„í„°
        if food_type:
            english_food_type = translate_to_english(food_type)
            food_type_terms = [food_type, english_food_type] if english_food_type != food_type else [food_type]
            food_type_conditions = []
            for term in food_type_terms:
                food_type_conditions.append("LOWER(ont_food_type) LIKE LOWER(?)")
                params.append(f"%{term}%")
            sql += f" AND ({' OR '.join(food_type_conditions)})"
        
        # ğŸ†• ì˜¤ì—¼ë¬¼ì§ˆ OR ì¡°ê±´ (ont_contaminant í•„ë“œ ì‚¬ìš©)
        if contaminants:
            contaminant_conditions = []
            for contaminant in contaminants:
                english_contaminant = translate_to_english(contaminant)
                contaminant_terms = [contaminant, english_contaminant] if english_contaminant != contaminant else [contaminant]
                
                for term in contaminant_terms:
                    contaminant_conditions.append("LOWER(ont_contaminant) LIKE LOWER(?)")
                    params.append(f"%{term}%")
            
            sql += f" AND ({' OR '.join(contaminant_conditions)})"
        
        # ê¸°ì¡´ í¬í•¨ ì¡°ê±´ (ont_contaminant ì¶”ê°€)
        if include_conditions:
            expanded_include = []
            for condition in include_conditions:
                expanded_include.append(condition)
                translated = translate_to_english(condition)
                if translated != condition:
                    expanded_include.append(translated)
            
            include_sql = []
            for condition in expanded_include:
                include_sql.append("""(
                    LOWER(ont_recall_reason) LIKE LOWER(?) OR 
                    LOWER(ont_food_type) LIKE LOWER(?) OR 
                    LOWER(ont_allergen) LIKE LOWER(?) OR
                    LOWER(ont_contaminant) LIKE LOWER(?) OR  # ğŸ†• ì¶”ê°€
                    LOWER(ont_food) LIKE LOWER(?)
                )""")
                params.extend([f"%{condition}%"] * 5)
            
            sql += " AND (" + " OR ".join(include_sql) + ")"
        
        # ê¸°ì¡´ ì œì™¸ ì¡°ê±´ë“¤...
        
        sql += " ORDER BY effective_date DESC LIMIT 10"
        
        print(f"ğŸ”§ ê°œì„ ëœ í•„í„°ë§ SQL: {sql}")
        print(f"ğŸ”§ íŒŒë¼ë¯¸í„°: {params}")
        
        cursor = sqlite_conn.cursor()
        cursor.execute(sql, params)
        results = cursor.fetchall()
        
        # ê²°ê³¼ í¬ë§·íŒ…
        cases = []
        for row in results:
            cases.append({
                "title": row["title"],
                "company": row["ont_company"],
                "food_type": row["ont_food_type"],
                "food_product": row["ont_food"],
                "reason": row["ont_recall_reason"],
                "contaminant": row["ont_contaminant"],  # ğŸ†• ì¶”ê°€
                "allergen": row["ont_allergen"],
                "date": row["effective_date"],
                "url": row["url"]
            })
        
        return {
            "cases": cases,
            "total_count": len(cases),
            "include_conditions": include_conditions or [],
            "exclude_conditions": exclude_conditions or [],
            "contaminants": contaminants or [],  # ğŸ†• ì¶”ê°€
            "query_type": "enhanced_filtered_search"
        }
        
    except Exception as e:
        return {"error": f"í•„í„°ë§ ì˜¤ë¥˜: {e}"}

@tool  
def compare_years(year1: str, year2: str, 
                 analysis_type: str = "total") -> Dict[str, Any]:
    """ì—°ë„ë³„ ë¹„êµ ë¶„ì„ (ìì—°ì–´ ë‚ ì§œ ì§€ì› ê°•í™”)"""
    
    sqlite_conn, _, _ = _get_system_components()
    
    if not sqlite_conn:
        return {"error": "SQLite ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨"}
    
    try:
        # ğŸš€ í–¥ìƒëœ ë‚ ì§œ ë³€í™˜ (ë” ëª…í™•í•œ ë¡œì§)
        actual_year1 = parse_relative_dates(year1)
        actual_year2 = parse_relative_dates(year2)
        
        # ğŸ†• ë‚ ì§œ ë³€í™˜ ê²€ì¦
        if not actual_year1.isdigit() or not actual_year2.isdigit():
            return {"error": f"ë‚ ì§œ ë³€í™˜ ì‹¤íŒ¨: '{year1}' â†’ {actual_year1}, '{year2}' â†’ {actual_year2}"}
        
        print(f"ğŸ”§ ì—°ë„ ë³€í™˜ í™•ì¸: '{year1}' â†’ {actual_year1}, '{year2}' â†’ {actual_year2}")
        
        cursor = sqlite_conn.cursor()
        
        # ê° ì—°ë„ë³„ ë°ì´í„° ì¡°íšŒ
        results = {}
        for original_year, actual_year in [(year1, actual_year1), (year2, actual_year2)]:
            
            # ğŸ†• ì—°ë„ë³„ ë°ì´í„° ì¡´ì¬ í™•ì¸
            cursor.execute("SELECT COUNT(*) as total FROM recalls WHERE strftime('%Y', effective_date) = ?", [actual_year])
            total_count = cursor.fetchone()["total"]
            
            if analysis_type == "total":
                results[f"{original_year}({actual_year})"] = {
                    "total": total_count,
                    "year": actual_year  # ğŸ†• ëª…ì‹œì  ì—°ë„ ì¶”ê°€
                }
                
            elif analysis_type == "reasons":
                # ğŸ”§ ì˜¬ë°”ë¥¸ ì»¬ëŸ¼ëª… ì‚¬ìš©
                cursor.execute("""
                    SELECT ont_recall_reason, COUNT(*) as count 
                    FROM recalls 
                    WHERE strftime('%Y', effective_date) = ? AND ont_recall_reason IS NOT NULL
                    GROUP BY ont_recall_reason 
                    ORDER BY count DESC 
                    LIMIT 5
                """, [actual_year])
                
                reasons = [{"reason": row["ont_recall_reason"], "count": row["count"]} for row in cursor.fetchall()]
                results[f"{original_year}({actual_year})"] = {
                    "top_reasons": reasons,
                    "total_with_reasons": len(reasons),
                    "year": actual_year  # ğŸ†• ëª…ì‹œì  ì—°ë„ ì¶”ê°€
                }
        
        # ğŸ†• ë³€í™”ìœ¨ ê³„ì‚° ì¶”ê°€ (total íƒ€ì…ì¼ ë•Œ)
        change_info = {}
        if analysis_type == "total":
            year1_count = results[f"{year1}({actual_year1})"]["total"]
            year2_count = results[f"{year2}({actual_year2})"]["total"]
            change = year2_count - year1_count
            change_percent = (change / year1_count * 100) if year1_count > 0 else 0
            
            change_info = {
                "change": change,
                "change_percent": round(change_percent, 1),
                "trend": "ì¦ê°€" if change > 0 else "ê°ì†Œ" if change < 0 else "ë³€í™”ì—†ìŒ"
            }
        
        return {
            "comparison": results,
            "year1": f"{year1}({actual_year1})",
            "year2": f"{year2}({actual_year2})",
            "analysis_type": analysis_type,
            "actual_years": [actual_year1, actual_year2],
            "change_info": change_info,  # ğŸ†• ë³€í™” ì •ë³´ ì¶”ê°€
            "query_type": "enhanced_year_comparison"
        }
        
    except Exception as e:
        print(f"âŒ ì—°ë„ ë¹„êµ ì˜¤ë¥˜: {e}")
        return {"error": f"ì—°ë„ ë¹„êµ ì˜¤ë¥˜: {e}"}

# ======================
# ë©”ì¸ ì‹œìŠ¤í…œ í´ë˜ìŠ¤
# ======================

class FunctionCallRecallSystem:
    """Function Calling ê¸°ë°˜ í•˜ì´ë¸Œë¦¬ë“œ ë¦¬ì½œ ì‹œìŠ¤í…œ - ì „ë¬¸ í”„ë¡¬í”„íŠ¸ í†µí•©"""
    
    def __init__(self):
        self.tools = [
            count_recalls, rank_by_field, get_monthly_trend, 
            compare_periods, search_recall_cases, filter_by_conditions,
            compare_years, exclude_contaminant_search 
        ]
        
        # OpenAI Function Calling ëª¨ë¸
        self.llm = ChatOpenAI(
            model="gpt-4o-mini",
            temperature=0
        ).bind_tools(self.tools)
        
        # ğŸ†• ë‹µë³€ ìƒì„±ìš© LLM (í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì ìš©)
        self.answer_llm = ChatOpenAI(
            model="gpt-4o-mini", 
            temperature=0.3
        )
    
    def process_question(self, question: str, chat_history: List = None) -> Dict[str, Any]:
        """Function Callingìœ¼ë¡œ ì§ˆë¬¸ ì²˜ë¦¬ - ê¸°ì¡´ê³¼ ë™ì¼"""
        
        if chat_history is None:
            chat_history = []
        
        try:
            # í•˜ì´ë¸Œë¦¬ë“œ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ (ê¸°ì¡´ê³¼ ë™ì¼)
            system_prompt = """
ë‹¹ì‹ ì€ FDA ë¦¬ì½œ ë°ì´í„° ì „ë¬¸ ë¶„ì„ê°€ì…ë‹ˆë‹¤. 
ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬ ì ì ˆí•œ í•¨ìˆ˜ë“¤ì„ í˜¸ì¶œí•´ì„œ ì •í™•í•œ ë‹µë³€ì„ ì œê³µí•˜ì„¸ìš”.

ğŸ”§ ChromaDB ê²€ìƒ‰ ì‹œ ì£¼ì˜ì‚¬í•­:
- í•œêµ­ì–´ ì§ˆë¬¸ì´ì§€ë§Œ ë°ì´í„°ëŠ” ì˜ì–´ë¡œ ì €ì¥ë˜ì–´ ìˆìŒ
- ê²€ìƒ‰ ì‹œ ì˜ì–´ í‚¤ì›Œë“œ ìš°ì„  ì‚¬ìš©
- "ì†ŒìŠ¤ ë³µí•©ì‹í’ˆ" â†’ "sauce Processed Foods"ë¡œ ê²€ìƒ‰

ğŸ—“ï¸ í˜„ì¬ ì‹œì  ì •ë³´ (ìë™ ì—…ë°ì´íŠ¸):
- í˜„ì¬ ì—°ë„: {current_year}ë…„
- ì‘ë…„: {last_year}ë…„  
- ì¬ì‘ë…„: {two_years_ago}ë…„

âš ï¸ **ë‚ ì§œ í•¨ìˆ˜ í˜¸ì¶œ ì‹œ ì ˆëŒ€ ê·œì¹™**:
- ì‚¬ìš©ìê°€ "ì‘ë…„"ì´ë¼ê³  í•˜ë©´ â†’ year1="ì‘ë…„" ë˜ëŠ” year2="ì‘ë…„"ìœ¼ë¡œ ê·¸ëŒ€ë¡œ ì „ë‹¬
- ì‚¬ìš©ìê°€ "ì˜¬í•´"ë¼ê³  í•˜ë©´ â†’ year1="ì˜¬í•´" ë˜ëŠ” year2="ì˜¬í•´"ë¡œ ê·¸ëŒ€ë¡œ ì „ë‹¬  
- ì ˆëŒ€ë¡œ "ì‘ë…„"ì„ "2024"ë¡œ ë°”ê¾¸ê±°ë‚˜ "ì˜¬í•´"ë¥¼ "2025"ë¡œ ë°”ê¾¸ì§€ ë§ê³  ì›ë³¸ ê·¸ëŒ€ë¡œ ì „ë‹¬

âŒ ì˜ëª»ëœ í˜¸ì¶œ:
- compare_periods(period1="2024", period2="2025")  â† ì´ë ‡ê²Œ í•˜ì§€ ë§ˆì„¸ìš”
- compare_years(year1="2024", year2="2025")  â† ì´ë ‡ê²Œ í•˜ì§€ ë§ˆì„¸ìš”

âœ… ì˜¬ë°”ë¥¸ í˜¸ì¶œ:
- compare_periods(period1="ì‘ë…„", period2="ì˜¬í•´")  â† ì´ë ‡ê²Œ í•˜ì„¸ìš”
- compare_years(year1="ì‘ë…„", year2="ì˜¬í•´")  â† ì´ë ‡ê²Œ í•˜ì„¸ìš”

ğŸ¯ í•¨ìˆ˜ ì„ íƒ ê°€ì´ë“œë¼ì¸:

1. **SQLite í•¨ìˆ˜** (ìˆ˜ì¹˜í˜•/í†µê³„ ì§ˆë¬¸):
   - "ì´ ê±´ìˆ˜", "ëª‡ ê±´" â†’ count_recalls()
   - "ìƒìœ„ Nê°œ", "ìˆœìœ„", "ê°€ì¥ ë§ì€" â†’ rank_by_field()  
   - "ì›”ë³„ íŠ¸ë Œë“œ", "ì¦ê°€/ê°ì†Œ" â†’ get_monthly_trend()
   - "2023ë…„ vs 2024ë…„" â†’ compare_periods()
   - "ì‘ë…„ê³¼ ì˜¬í•´ ë¦¬ì½œ ì›ì¸ ë¹„êµ" â†’ compare_years("ì‘ë…„", "ì˜¬í•´", analysis_type="reasons")

2. **ChromaDB í•¨ìˆ˜** (ë‚´ìš©/ì‚¬ë¡€ ê²€ìƒ‰):
   - "ì‚¬ë¡€ ì•Œë ¤ì¤˜", "ì–´ë–¤ ì œí’ˆ", "êµ¬ì²´ì ì¸ ë‚´ìš©" â†’ search_recall_cases()

ì˜ˆì‹œ:
- "ì‘ë…„ê³¼ ì˜¬í•´ ë¦¬ì½œ ë¹„êµ" â†’ compare_periods("ì‘ë…„", "ì˜¬í•´")  # {last_year} vs {current_year}
- "ì „ë…„ ëŒ€ë¹„ ì¦ê°€ìœ¨" â†’ compare_periods("ì „ë…„", "í˜„ì¬")      # {last_year} vs {current_year}

**ì¤‘ìš”**: ì‘ë…„={last_year}ë…„, ì˜¬í•´={current_year}ë…„ìœ¼ë¡œ ì •í™•íˆ ì¸ì‹í•˜ì—¬ í•¨ìˆ˜ í˜¸ì¶œí•˜ì„¸ìš”.
**íŠ¹ì • ì‹í’ˆ ì¹´í…Œê³ ë¦¬(ê³„ë€, ìš°ìœ , ê²¬ê³¼ë¥˜ ë“±) ì§ˆë¬¸ì€ keyword íŒŒë¼ë¯¸í„°ë¡œ í†µí•© ê²€ìƒ‰í•˜ì„¸ìš”.**

3. **ì¡°ê±´ë³„ í•„í„°ë§** (ë³µí•© ì¡°ê±´ + OR ì¡°ê±´ ì§€ì›):
   - "A ì¤‘ì—ì„œ Bë¥¼ ì œì™¸í•œ" â†’ filter_by_conditions()
   - "í•´ì‚°ë¬¼ì—ì„œ ì‚´ëª¨ë„¬ë¼ ë˜ëŠ” ë¦¬ìŠ¤í…Œë¦¬ì•„" â†’ filter_by_conditions(food_type="í•´ì‚°ë¬¼", contaminants=["ì‚´ëª¨ë„¬ë¼", "ë¦¬ìŠ¤í…Œë¦¬ì•„"])
   - "ê³¼ìë¥˜ì—ì„œ ê²¬ê³¼ë¥˜ ë˜ëŠ” ìš°ìœ  ì•Œë ˆë¥´ê²" â†’ filter_by_conditions(food_type="ê³¼ìë¥˜", include_conditions=["ê²¬ê³¼ë¥˜", "ìš°ìœ "])

ì˜ˆì‹œ:
- "í•´ì‚°ë¬¼ ì¤‘ì—ì„œ ì‚´ëª¨ë„¬ë¼ê·  ë˜ëŠ” ë¦¬ìŠ¤í…Œë¦¬ì•„ê°€ ì›ì¸ì¸ ì‚¬ë¡€" â†’ filter_by_conditions(food_type="í•´ì‚°ë¬¼", contaminants=["ì‚´ëª¨ë„¬ë¼", "ë¦¬ìŠ¤í…Œë¦¬ì•„"])
- "ìœ ì œí’ˆì—ì„œ í™”í•™ë¬¼ì§ˆ ë˜ëŠ” ì´ë¬¼ì§ˆ" â†’ filter_by_conditions(food_type="ìœ ì œí’ˆ", contaminants=["í™”í•™ë¬¼ì§ˆ", "ì´ë¬¼ì§ˆ"])

4. **íŠ¹ìˆ˜ ê²€ìƒ‰** (ì œì™¸ ì¡°ê±´):
   - "Aë¥¼ ì œì™¸í•œ B" â†’ exclude_contaminant_search()
   - "ì‚´ëª¨ë„¬ë¼ ë¹¼ê³  ì„¸ê·  ì˜¤ì—¼" â†’ exclude_contaminant_search("bacterial", "salmonella")

5. **í†µí•© í‚¤ì›Œë“œ ê²€ìƒ‰** (íŠ¹ì • ì¹´í…Œê³ ë¦¬/ì‹í’ˆ ê´€ë ¨):
   - "ê³„ë€ ê´€ë ¨ ë¦¬ì½œ ì´ ëª‡ ê±´?" â†’ count_recalls(keyword="ê³„ë€")
   - "ìš°ìœ  ì œí’ˆ ë¦¬ì½œ" â†’ count_recalls(keyword="ìš°ìœ ")  
   - "ê²¬ê³¼ë¥˜ ì´ ê±´ìˆ˜" â†’ count_recalls(keyword="ê²¬ê³¼ë¥˜")
   - keyword íŒŒë¼ë¯¸í„°ëŠ” ëª¨ë“  ê´€ë ¨ í•„ë“œì—ì„œ ìë™ í†µí•© ê²€ìƒ‰

ğŸ”§ ì¤‘ìš”í•œ ë§¤í•‘:
- "ë³µí•© ê°€ê³µì‹í’ˆ" = "Processed Foods"
- "ì£¼ìš” ë¦¬ì½œ ì‚¬ìœ " = field="ont_recall_reason"ìœ¼ë¡œ ìˆœìœ„ ë¶„ì„
- "ì‚´ëª¨ë„¬ë¼" â†’ ChromaDBì—ì„œ ì˜ë¯¸ì  ê²€ìƒ‰

ğŸ”§ ë‹¤ì¸µ í•„ë“œ ê²€ìƒ‰:
- "ìœ¡ë¥˜ vs í•´ì‚°ë¬¼" â†’ rank_by_field(field="food") # ont_food ê²€ìƒ‰
- "ì œí’ˆ ìœ í˜•ë³„" â†’ rank_by_field(field="food_type") # ont_food_type ê²€ìƒ‰

ğŸ”§ í‚¤ì›Œë“œ í†µí•© ê²€ìƒ‰:
- "ê³„ë€", "ìš°ìœ ", "ê²¬ê³¼ë¥˜" ë“± íŠ¹ì • ì‹í’ˆ ì¹´í…Œê³ ë¦¬ ì§ˆë¬¸
- ont_food_type, ont_food, ont_allergen, ont_contaminant ë“± ëª¨ë“  ê´€ë ¨ í•„ë“œì—ì„œ ë™ì‹œ ê²€ìƒ‰  # ìˆ˜ì •
- í•œêµ­ì–´ í‚¤ì›Œë“œë¥¼ ì˜ì–´ë¡œ ìë™ í™•ì¥ ("ê³„ë€" â†’ "egg", "eggs")

ğŸ—“ï¸ ìì—°ì–´ ë‚ ì§œ ì§€ì›:
- "ì‘ë…„ê³¼ ì˜¬í•´" â†’ ìë™ìœ¼ë¡œ 2024ë…„ê³¼ 2025ë…„ìœ¼ë¡œ ë³€í™˜
- "ì „ë…„ ëŒ€ë¹„" â†’ 2024ë…„ê³¼ 2025ë…„ ë¹„êµ
- "ì§€ë‚œí•´" â†’ 2024ë…„

ì˜ˆì‹œ:
- "2024ë…„ ì´ ë¦¬ì½œ ê±´ìˆ˜ëŠ”?" â†’ count_recalls(year="2024")
- "ê³„ë€ ê´€ë ¨ ë¦¬ì½œ ì´ ëª‡ ê±´?" â†’ count_recalls(keyword="ê³„ë€")
- "ìš°ìœ  ì œí’ˆ 2023ë…„ ë¦¬ì½œ" â†’ count_recalls(keyword="ìš°ìœ ", year="2023")
- "ë³µí•© ê°€ê³µì‹í’ˆ ì£¼ìš” ë¦¬ì½œ ì‚¬ìœ  4ê°€ì§€" â†’ rank_by_field(field="ont_recall_reason", food_type="Processed Foods", limit=4)
- "ì‚´ëª¨ë„¬ë¼ ê´€ë ¨ ì‚¬ë¡€ ì•Œë ¤ì¤˜" â†’ search_recall_cases("ì‚´ëª¨ë„¬ë¼")
- "ì†ŒìŠ¤ë¥¼ í¬í•¨í•œ ë³µí•©ì‹í’ˆ ì‚¬ë¡€" â†’ search_recall_cases("sauce processed food")
- "ì‘ë…„ê³¼ ì˜¬í•´ ë¦¬ì½œ ë¹„êµ" â†’ compare_periods("ì‘ë…„", "ì˜¬í•´")
- "ì „ë…„ ëŒ€ë¹„ ì¦ê°€ìœ¨" â†’ compare_periods("ì „ë…„", "í˜„ì¬")

**ìˆ˜ì¹˜ëŠ” SQLite, ë‚´ìš© ê²€ìƒ‰ì€ ChromaDBë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.**
**íŠ¹ì • ì‹í’ˆ ì¹´í…Œê³ ë¦¬(ê³„ë€, ìš°ìœ , ê²¬ê³¼ë¥˜ ë“±) ì§ˆë¬¸ì€ keyword íŒŒë¼ë¯¸í„°ë¡œ í†µí•© ê²€ìƒ‰í•˜ì„¸ìš”.**
"""
            
            # ëŒ€í™” ë©”ì‹œì§€ êµ¬ì„±
            messages = [
                {"role": "system", "content": system_prompt},
                *[{"role": msg.type, "content": msg.content} for msg in chat_history[-6:]],
                {"role": "user", "content": question}
            ]
            
            # Function Calling ì‹¤í–‰
            response = self.llm.invoke(messages)
            
            # í•¨ìˆ˜ í˜¸ì¶œì´ ìˆëŠ” ê²½ìš° ì‹¤í–‰
            if hasattr(response, 'tool_calls') and response.tool_calls:
                print(f"ğŸ”§ Function Calls: {len(response.tool_calls)}ê°œ")
                
                tool_results = []
                for tool_call in response.tool_calls:
                    func_name = tool_call['name']
                    func_args = tool_call.get('args', {})
                    
                    print(f"  â†’ {func_name}({func_args})")
                    
                    # í•¨ìˆ˜ ì‹¤í–‰
                    for tool in self.tools:
                        if tool.name == func_name:
                            result = tool.invoke(func_args)
                            tool_results.append({
                                "function": func_name,
                                "args": func_args,
                                "result": result
                            })
                            break
                
                # ğŸ†• ì „ë¬¸ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ìœ¼ë¡œ ìµœì¢… ë‹µë³€ ìƒì„±
                final_answer = self._generate_final_answer(question, tool_results)
                
                return {
                    "answer": final_answer,
                    "function_calls": tool_results,
                    "processing_type": "function_calling"
                }
            else:
                # ì¼ë°˜ ë‹µë³€
                return {
                    "answer": response.content,
                    "function_calls": [],
                    "processing_type": "direct_answer"
                }
                
        except Exception as e:
            return {
                "answer": f"ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}",
                "function_calls": [],
                "processing_type": "error"
            }
    
    def _generate_final_answer(self, question: str, tool_results: List[Dict]) -> str:
        """ì „ë¬¸ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì„ í™œìš©í•œ ë‹µë³€ ìƒì„±"""
        
        if not tool_results:
            return "ì£„ì†¡í•©ë‹ˆë‹¤. ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        # ğŸ†• ì§ˆë¬¸ ìœ í˜•ë³„ í”„ë¡¬í”„íŠ¸ ì„ íƒ ë° ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
        answer_context = self._build_answer_context(tool_results)
        selected_prompt = self._select_prompt_template(question, tool_results)
        
        try:
            # ğŸ†• ì „ë¬¸ í”„ë¡¬í”„íŠ¸ë¡œ ìµœì¢… ë‹µë³€ ìƒì„±
            final_prompt = selected_prompt.format(
                question=question,
                **answer_context
            )
            
            response = self.answer_llm.invoke([
                {"role": "system", "content": "ë‹¹ì‹ ì€ FDA ë¦¬ì½œ ë°ì´í„° ì „ë¬¸ ë¶„ì„ê°€ì…ë‹ˆë‹¤."},
                {"role": "user", "content": final_prompt}
            ])
            
            return response.content
            
        except Exception as e:
            print(f"ë‹µë³€ ìƒì„± ì˜¤ë¥˜: {e}")
            # í´ë°±: ê¸°ì¡´ ë°©ì‹ ì‚¬ìš©
            return self._generate_basic_answer(question, tool_results)
    
    def _select_prompt_template(self, question: str, tool_results: List[Dict]) -> str:
        """ì§ˆë¬¸ê³¼ ê²°ê³¼ ìœ í˜•ì— ë”°ë¥¸ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì„ íƒ"""
        
        # ì‚¬ë¡€ ê²€ìƒ‰ ê²°ê³¼ê°€ ìˆëŠ” ê²½ìš°
        if any("search_recall_cases" == tr["function"] for tr in tool_results):
            return RecallPrompts.RECALL_ANSWER
        
        # ìˆ˜ì¹˜/í†µê³„ ë¶„ì„ ê²°ê³¼
        elif any(tr["function"] in ["count_recalls", "rank_by_field", "get_monthly_trend"] 
                for tr in tool_results):
            return RecallPrompts.NUMERICAL_ANSWER
        
        # ë…¼ë¦¬ ì—°ì‚°/ë¹„êµ ë¶„ì„ ê²°ê³¼  
        elif any(tr["function"] in ["compare_periods", "compare_years", 
                                   "filter_by_conditions", "exclude_contaminant_search"] 
                for tr in tool_results):
            return RecallPrompts.LOGICAL_ANSWER
        
        # ê¸°ë³¸: ë¦¬ì½œ ë‹µë³€ í…œí”Œë¦¿
        else:
            return RecallPrompts.RECALL_ANSWER
    
    def _build_answer_context(self, tool_results: List[Dict]) -> Dict[str, str]:
        """í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ìš© ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±"""
        
        context = {}
        
        # ì‚¬ë¡€ ê²€ìƒ‰ ê²°ê³¼ ì²˜ë¦¬
        search_results = [tr for tr in tool_results if tr["function"] == "search_recall_cases"]
        if search_results:
            cases = search_results[0]["result"].get("cases", [])
            context["recall_context"] = self._format_cases_for_prompt(cases)
        
        # ìˆ˜ì¹˜ ë¶„ì„ ê²°ê³¼ ì²˜ë¦¬
        numerical_results = [tr for tr in tool_results 
                           if tr["function"] in ["count_recalls", "rank_by_field", "get_monthly_trend"]]
        if numerical_results:
            context.update(self._format_numerical_for_prompt(numerical_results))
        
        # ë…¼ë¦¬ ë¶„ì„ ê²°ê³¼ ì²˜ë¦¬
        logical_results = [tr for tr in tool_results 
                         if tr["function"] in ["compare_periods", "compare_years", 
                                              "filter_by_conditions", "exclude_contaminant_search"]]
        if logical_results:
            context.update(self._format_logical_for_prompt(logical_results))
        
        return context
    
    def _format_cases_for_prompt(self, cases: List[Dict]) -> str:
        """ì‚¬ë¡€ ë°ì´í„°ë¥¼ í”„ë¡¬í”„íŠ¸ìš© í…ìŠ¤íŠ¸ë¡œ ë³€í™˜"""
        
        if not cases:
            return "ê´€ë ¨ ì‚¬ë¡€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

        formatted_cases = []
        
        for i, case in enumerate(cases[:8], 1):  # ìµœëŒ€ 8ê±´
            case_text = f"""ì‚¬ë¡€ {i}:
- íšŒì‚¬: {case.get('company', 'Unknown')}
- ì œí’ˆ: {case.get('food', case.get('food_product', 'N/A'))}
- ë¦¬ì½œ ì‚¬ìœ : {case.get('reason', 'N/A')}
- ì•Œë ˆë¥´ê²: {case.get('allergen', 'N/A')}
- ì˜¤ì—¼ë¬¼ì§ˆ: {case.get('contaminant', 'N/A')}
- ë‚ ì§œ: {case.get('date', 'N/A')}
- URL: {case.get('url', 'N/A')}"""
            formatted_cases.append(case_text.strip())
        
        return "\n\n".join(formatted_cases)
    
    def _format_numerical_for_prompt(self, numerical_results: List[Dict]) -> Dict[str, str]:
        """ìˆ˜ì¹˜ ë¶„ì„ ê²°ê³¼ë¥¼ í”„ë¡¬í”„íŠ¸ìš©ìœ¼ë¡œ ë³€í™˜"""
        
        context = {}
        
        for tool_result in numerical_results:
            func_name = tool_result["function"]
            result = tool_result["result"]
            
            if func_name == "count_recalls":
                context["analysis_type"] = "ë¦¬ì½œ ê±´ìˆ˜ í†µê³„"
                context["result"] = f"ì´ {result.get('count', 0):,}ê±´"
                context["description"] = f"í•„í„° ì¡°ê±´: {result.get('filters', {})}"
                
            elif func_name == "rank_by_field":
                context["analysis_type"] = f"{result.get('field', '')}ë³„ ìƒìœ„ ìˆœìœ„"
                ranking = result.get("ranking", [])
                context["result"] = "\n".join([
                    f"{i+1}ìœ„: {item['name']} ({item['count']}ê±´)" 
                    for i, item in enumerate(ranking[:10])
                ])
                context["description"] = f"ì´ {len(ranking)}ê°œ í•­ëª© ë¶„ì„"
                
            elif func_name == "get_monthly_trend":
                context["analysis_type"] = "ì›”ë³„ ë¦¬ì½œ íŠ¸ë Œë“œ"
                trend = result.get("trend", [])
                context["result"] = "\n".join([
                    f"{item['month']}: {item['count']}ê±´" 
                    for item in trend[:12]
                ])
                context["description"] = f"ìµœê·¼ {len(trend)}ê°œì›” ë°ì´í„°"
        
        return context
    
    def _format_logical_for_prompt(self, logical_results: List[Dict]) -> Dict[str, str]:
        """ë…¼ë¦¬ ë¶„ì„ ê²°ê³¼ë¥¼ í”„ë¡¬í”„íŠ¸ìš©ìœ¼ë¡œ ë³€í™˜"""
        
        context = {}
        
        for tool_result in logical_results:
            func_name = tool_result["function"]
            result = tool_result["result"]
            
            if func_name == "compare_periods":
                context["operation"] = "ê¸°ê°„ë³„ ë¹„êµ ë¶„ì„"
                period1 = result.get("period1", {})
                period2 = result.get("period2", {})
                change_percent = result.get("change_percent", 0)
                
                context["result"] = {
                    "period1_data": period1,
                    "period2_data": period2, 
                    "change_percent": change_percent
                }
                context["description"] = f"ë³€í™”ìœ¨: {change_percent:+.1f}%"
                
            elif func_name == "compare_years":
                context["operation"] = "ì—°ë„ë³„ ìƒì„¸ ë¹„êµ"
                comparison = result.get("comparison", {})
                context["result"] = comparison
                context["description"] = f"{result.get('year1', '')} vs {result.get('year2', '')} ë¶„ì„"
                
            elif func_name == "filter_by_conditions":
                context["operation"] = "ì¡°ê±´ë³„ í•„í„°ë§"
                cases = result.get("cases", [])
                context["result"] = f"í•„í„°ë§ëœ ì‚¬ë¡€ {len(cases)}ê±´"
                context["description"] = f"í¬í•¨ì¡°ê±´: {result.get('include_conditions', [])}, ì œì™¸ì¡°ê±´: {result.get('exclude_conditions', [])}"
                
            elif func_name == "exclude_contaminant_search":
                context["operation"] = "ì œì™¸ ì¡°ê±´ ê²€ìƒ‰"
                cases = result.get("cases", [])
                context["result"] = f"ì œì™¸ ê²€ìƒ‰ ê²°ê³¼ {len(cases)}ê±´"
                context["description"] = f"'{result.get('exclude_contaminant', '')}'ë¥¼ ì œì™¸í•œ '{result.get('include_reason', '')}' ê²€ìƒ‰"
        
        # JSONì„ ë¬¸ìì—´ë¡œ ë³€í™˜
        context["result"] = str(context.get("result", ""))
        context["related_links"] = "FDA ê³µì‹ ë°ì´í„°ë² ì´ìŠ¤ ê¸°ë°˜ ë¶„ì„"
        
        return context
    
    def _generate_basic_answer(self, question: str, tool_results: List[Dict]) -> str:
        """í´ë°±ìš© ê¸°ë³¸ ë‹µë³€ ìƒì„± (ê¸°ì¡´ ë°©ì‹)"""
        
        answer_parts = []
        answer_parts.append("## ğŸ” FDA ë¦¬ì½œ ë°ì´í„° ë¶„ì„ ê²°ê³¼")
        answer_parts.append("")
        
        for tool_result in tool_results:
            func_name = tool_result["function"] 
            result = tool_result["result"]
            
            if "error" in result:
                answer_parts.append(f"âš ï¸ {func_name} ì˜¤ë¥˜: {result['error']}")
                continue
        
        return "\n".join(answer_parts) if len(answer_parts) > 2 else "ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

# ======================
# ì™¸ë¶€ ì¸í„°í˜ì´ìŠ¤ í•¨ìˆ˜ë“¤
# ======================

def create_function_calling_system():
    """Function Calling ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
    try:
        return FunctionCallRecallSystem()
    except Exception as e:
        print(f"Function Calling ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì˜¤ë¥˜: {e}")
        return None

def ask_recall_question_fc(question: str, chat_history: List = None) -> Dict[str, Any]:
    """Function Calling ê¸°ë°˜ ì§ˆë¬¸ ì²˜ë¦¬"""
    system = create_function_calling_system()
    if system:
        return system.process_question(question, chat_history)
    else:
        return {
            "answer": "ì‹œìŠ¤í…œ ì´ˆê¸°í™”ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.",
            "function_calls": [],
            "processing_type": "error"
        }

def ask_recall_question(question: str, chat_history: List = None) -> Dict[str, Any]:
    """í†µí•©ëœ ë¦¬ì½œ ì§ˆë¬¸ ì²˜ë¦¬ í•¨ìˆ˜ (tab_recall.py í˜¸í™˜ìš©)"""
    
    if chat_history is None:
        chat_history = []
    
    try:
        # Function Calling ì‹œìŠ¤í…œ ì‚¬ìš©
        result = ask_recall_question_fc(question, chat_history)
        
        # ê¸°ì¡´ UI í˜¸í™˜ í˜•ì‹ìœ¼ë¡œ ë°˜í™˜
        return {
            "answer": result["answer"],
            "recall_documents": [],
            "chat_history": chat_history + [
                HumanMessage(content=question),
                AIMessage(content=result["answer"])
            ],
            "processing_type": result["processing_type"],
            "function_calls": result.get("function_calls", []),
            "has_realtime_data": True,
            "realtime_count": len(result.get("function_calls", []))
        }
        
    except Exception as e:
        return {
            "answer": f"ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}",
            "recall_documents": [],
            "chat_history": chat_history,
            "processing_type": "error",
            "function_calls": []
        }